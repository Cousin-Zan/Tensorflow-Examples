{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'2.3.0'"
      ]
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "source": [
    "创建一个自定义的全连接层（dense）"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(tf.keras.layers.Layer):\n",
    "    def __init__(self, units=32,input_dim=32):\n",
    "        super().__init__()\n",
    "        self.units = units\n",
    "        self.input_dim = input_dim\n",
    "\n",
    "        self.w = self.add_variable(name='w',\n",
    "            shape=[self.input_dim, self.units], initializer=tf.random_normal_initializer(),trainable=True)\n",
    "        self.b = self.add_variable(name='b',\n",
    "            shape=[self.units], initializer=tf.zeros_initializer(),trainable=True)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        y_pred = tf.matmul(inputs, self.w) + self.b\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_linear = Linear(4, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[<tf.Variable 'w:0' shape=(2, 4) dtype=float32, numpy=\n",
       " array([[ 0.05543784, -0.07811399,  0.0345751 , -0.07654205],\n",
       "        [ 0.00211201,  0.07324024, -0.05754722,  0.02302237]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'b:0' shape=(4,) dtype=float32, numpy=array([0., 0., 0., 0.], dtype=float32)>]"
      ]
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "source": [
    "my_linear.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.ones((2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = my_linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 4), dtype=float32, numpy=\n",
       "array([[ 0.05754986, -0.00487375, -0.02297212, -0.05351968],\n",
       "       [ 0.05754986, -0.00487375, -0.02297212, -0.05351968]],\n",
       "      dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 56
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[<tf.Variable 'w:0' shape=(2, 4) dtype=float32, numpy=\n",
       " array([[ 0.05543784, -0.07811399,  0.0345751 , -0.07654205],\n",
       "        [ 0.00211201,  0.07324024, -0.05754722,  0.02302237]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'b:0' shape=(4,) dtype=float32, numpy=array([0., 0., 0., 0.], dtype=float32)>]"
      ]
     },
     "metadata": {},
     "execution_count": 57
    }
   ],
   "source": [
    "my_linear.weights"
   ]
  },
  {
   "source": [
    "还可以使用一种更加快捷的方式为层添加权重：add_weight()方法："
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(tf.keras.layers.Layer):\n",
    "    def __init__(self, units=32,input_dim=32):\n",
    "        super().__init__()\n",
    "        self.units = units\n",
    "        self.input_dim = input_dim\n",
    "\n",
    "        self.w = self.add_weight(\n",
    "            shape=(input_dim,units), \n",
    "            initializer='random_normal',\n",
    "            trainable=True\n",
    "        )\n",
    "        self.b = self.add_weight(\n",
    "            shape=(units,), \n",
    "            initializer='zeros',\n",
    "            trainable=True\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        y_pred = tf.matmul(inputs, self.w) + self.b\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.keras.layers.Dense(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "metadata": {},
     "execution_count": 60
    }
   ],
   "source": [
    "x.weights"
   ]
  },
  {
   "source": [
    "将权重创建推迟到得知输入的形状之后<br></br>在层的build(self,input_shape)方法中创建层的权重"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(tf.keras.layers.Layer):\n",
    "    def __init__(self, units=32):\n",
    "        super().__init__()\n",
    "        self.units = units\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.w = self.add_weight(\n",
    "            shape=(input_shape[-1],self.units), \n",
    "            initializer='random_normal',\n",
    "            trainable=True\n",
    "        )\n",
    "        self.b = self.add_weight(\n",
    "            shape=(self.units,), \n",
    "            initializer='zeros',\n",
    "            trainable=True\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        y_pred = tf.matmul(inputs, self.w) + self.b\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_linear = Linear(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "metadata": {},
     "execution_count": 63
    }
   ],
   "source": [
    "my_linear.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.ones((2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 4), dtype=float32, numpy=\n",
       "array([[ 0.05428372, -0.07787265, -0.10486257, -0.06847197],\n",
       "       [ 0.05428372, -0.07787265, -0.10486257, -0.06847197]],\n",
       "      dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 65
    }
   ],
   "source": [
    "my_linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[<tf.Variable 'linear_10/Variable:0' shape=(2, 4) dtype=float32, numpy=\n",
       " array([[ 0.12050934, -0.04452366, -0.07737461,  0.0138237 ],\n",
       "        [-0.06622562, -0.03334899, -0.02748796, -0.08229566]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'linear_10/Variable:0' shape=(4,) dtype=float32, numpy=array([0., 0., 0., 0.], dtype=float32)>]"
      ]
     },
     "metadata": {},
     "execution_count": 66
    }
   ],
   "source": [
    "my_linear.weights"
   ]
  },
  {
   "source": [
    "层的call()方法将在首次调用时自动运行构建训练函数"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 层可递归组合"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "如果将一个层实例分配为另一个层的特性，则外部层将开始跟踪内部层的权重。\n",
    "\n",
    "我们建议在init()方法中创建此类子层（由于子层通常具有构建方法，它们将与外部层同时构建）。"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPBlock(keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(MLPBlock, self).__init__()\n",
    "        self.lin_1 = Linear(32)\n",
    "        self.lin_2 = Linear(64)\n",
    "        self.lin_3 = Linear(1)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.lin_1(inputs)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.lin_2(x)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.lin_3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlp = MLPBlock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPBlock_2(keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(MLPBlock_2, self).__init__()\n",
    "        self.lin_1 = tf.keras.layers.Dense(32)\n",
    "        self.lin_2 = tf.keras.layers.Dense(64)\n",
    "        self.lin_3 = tf.keras.layers.Dense(32)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x1 = self.lin_1(inputs)\n",
    "        x1 = tf.nn.relu(x1)\n",
    "        x2 = self.lin_2(x1)\n",
    "        x2 = tf.nn.relu(x2)\n",
    "        x3 = self.lin_3(x2)\n",
    "        return tf.concat([x1, x3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPBlock_2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'MLPBlock_2' object has no attribute 'fit'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-78-831d650fbb04>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'MLPBlock_2' object has no attribute 'fit'"
     ]
    }
   ],
   "source": [
    "mlp.fit"
   ]
  },
  {
   "source": [
    "通常使用Layer类来定义内部计算块，并使用Model类来定义外部模型，即您将训练的对象。"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Model类具有与Layer相同的API，但有如下区别：\n",
    "\n",
    "它会公开内置训练、评估和预测循环（model.fit()、model.evaluate()、model.predict())。\n",
    "\n",
    "它会通过model.layer属性公开其内部层的列表。\n",
    "\n",
    "它会公开保存和序列化API（save()、save_weights()……）"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_model(keras.Model):\n",
    "    def __init__(self):\n",
    "        super(MLP_model, self).__init__()\n",
    "        self.lin_1 = tf.keras.layers.Dense(32)\n",
    "        self.lin_2 = tf.keras.layers.Dense(64)\n",
    "        self.lin_3 = tf.keras.layers.Dense(32)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x1 = self.lin_1(inputs)\n",
    "        x1 = tf.nn.relu(x1)\n",
    "        x2 = self.lin_2(x1)\n",
    "        x2 = tf.nn.relu(x2)\n",
    "        x3 = self.lin_3(x2)\n",
    "        return tf.concat([x1, x3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<bound method Model.fit of <__main__.MLP_model object at 0x0000026734993B50>>"
      ]
     },
     "metadata": {},
     "execution_count": 75
    }
   ],
   "source": [
    "model.fit"
   ]
  },
  {
   "source": [
    "因此，如果您想知道“我应该用Layer类还是Model类？”，\n",
    "\n",
    "请问自己：我是否需要在它上面调用fit()?\n",
    "\n",
    "我是否需要在它上面调用save()?\n",
    "\n",
    "如果是，则使用Model。如果不是（要么因为您的类只是更大系统中的一个块，要么因为您正在自己编写训练和保存代码），则使用Layer。"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}